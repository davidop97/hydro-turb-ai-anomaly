# ‚ö° Detector de Anomal√≠as en Turbinas Hidr√°ulicas

**Sistema de ML para detecci√≥n y clasificaci√≥n de anomal√≠as (desbalanceo vs desalineaci√≥n) en turbinas hidr√°ulicas Francis usando an√°lisis de residuos y clasificadores probabil√≠sticos.**

---

## üìã Tabla de Contenidos

- [Descripci√≥n General](#descripci√≥n-general)
- [Caracter√≠sticas](#caracter√≠sticas)
- [Arquitectura](#arquitectura)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Requisitos](#requisitos)
- [Instalaci√≥n](#instalaci√≥n)
- [Uso](#uso)
  - [Entrenar el Modelo](#entrenar-el-modelo)
  - [Entrenar Clasificadores](#entrenar-clasificadores)
  - [Hacer Predicciones](#hacer-predicciones)
  - [Ejecutar la Interfaz Web](#ejecutar-la-interfaz-web)
- [API REST (Legado)](#api-rest-legado)
- [Workflows de CI/CD](#workflows-de-cicd)
- [Deployment](#deployment)
- [Documentaci√≥n T√©cnica](#documentaci√≥n-t√©cnica)

---

## üéØ Descripci√≥n General

Este proyecto implementa un **sistema completo de machine learning** para la detecci√≥n de anomal√≠as en turbinas hidr√°ulicas. El sistema:

1. **Procesa datos de sensores** de vibraci√≥n (CSP, CSL, CTP, CTL) en diferentes velocidades (KPH)
2. **Entrena un modelo de residuos** usando polinomios c√∫bicos para capturar la vibraci√≥n base
3. **Entrena clasificadores probabil√≠sticos** (Linear, Logistic, GMM) para diferenciar:
   - **Desbalanceo**: Desequilibrio de masa rotacional
   - **Desalineaci√≥n**: Desalineaci√≥n del eje
4. **Calcula severidad** en tres niveles (Verde, Amarillo, Rojo) por sensor
5. **Proporciona visualizaci√≥n interactiva** mediante Streamlit

---

## ‚ú® Caracter√≠sticas

‚úÖ **Modelo de Residuos Robusto**: Ajuste polin√≥mico por sensor para capturar patrones base  
‚úÖ **3 Clasificadores Probabil√≠sticos**: Linear, Logistic, GMM - todos con validaci√≥n train/test  
‚úÖ **Severidad Multinivel**: Evaluaci√≥n por sensor con umbrales configurables  
‚úÖ **Interfaz Web Interactiva**: Streamlit con 3 tabs (Predicci√≥n, Gr√°ficas, Severidad)  
‚úÖ **Tracking de Experimentos**: MLflow para reproducibilidad  
‚úÖ **Dockerizado**: docker-compose con MLflow integrado  
‚úÖ **Deployed**: Streamlit Cloud en producci√≥n  

---

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Datos CSV (Sensores)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                               ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ EDA       ‚îÇ              ‚îÇ Preprocessing ‚îÇ
    ‚îÇ (eda.py)  ‚îÇ              ‚îÇ (pipeline.py) ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                               ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Modelo de Residuos (train)   ‚îÇ
         ‚îÇ  - Polinomios c√∫bicos         ‚îÇ
         ‚îÇ  - Por sensor                 ‚îÇ
         ‚îÇ  - residuals_CSP_v3.pkl       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Extracci√≥n de Features       ‚îÇ
         ‚îÇ  - 12 features estad√≠sticos   ‚îÇ
         ‚îÇ  - Por archivo entrenamiento  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ                    ‚îÇ                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Linear ‚îÇ          ‚îÇ Logistic ‚îÇ          ‚îÇ  GMM   ‚îÇ
‚îÇ (best) ‚îÇ          ‚îÇ          ‚îÇ          ‚îÇ        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îî‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ                    ‚îÇ                    ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Predicci√≥n en Datos Nuevos   ‚îÇ
         ‚îÇ  - Residuos por muestra       ‚îÇ
         ‚îÇ  - Probabilidades             ‚îÇ
         ‚îÇ  - Severidad por sensor       ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Streamlit UI                 ‚îÇ
         ‚îÇ  ‚îú‚îÄ Tab 1: Predicci√≥n Global  ‚îÇ
         ‚îÇ  ‚îú‚îÄ Tab 2: Gr√°ficas Sensores  ‚îÇ
         ‚îÇ  ‚îî‚îÄ Tab 3: Severidad Detalle  ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìÅ Estructura del Proyecto

```
hydro-turb-ai-anomaly/
‚îÇ
‚îú‚îÄ‚îÄ üìÇ src/
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ anomaly_detector.py          # Clase principal de detecci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ classifier.py                # Clasificadores (Linear/Logistic/GMM)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ residuals_model.py           # Modelo de residuos base
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sensor_selector.py           # Selecci√≥n de sensores
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ turb_predictor.py            # Predictor integrado
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ vibration_severity_checker.py # Evaluaci√≥n de severidad
‚îÇ   ‚îÇ
‚îÇ   ‚îú‚îÄ‚îÄ üìÇ preprocessing/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eda_loader.py                # Carga y EDA inicial
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pipeline.py                  # Pipeline de preprocesamiento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ utils.py                     # Utilidades
‚îÇ   ‚îÇ
‚îÇ   ‚îî‚îÄ‚îÄ üìÇ visualization/
‚îÇ       ‚îú‚îÄ‚îÄ charts.py                    # Gr√°ficos matplotlib
‚îÇ       ‚îú‚îÄ‚îÄ eda_plots.py                 # Plots exploratorios
‚îÇ       ‚îú‚îÄ‚îÄ plots.py                     # Plots adicionales
‚îÇ       ‚îî‚îÄ‚îÄ config.py                    # Configuraci√≥n de estilos
‚îÇ
‚îú‚îÄ‚îÄ üìÇ workflows/
‚îÇ   ‚îú‚îÄ‚îÄ eda.py                           # An√°lisis exploratorio de datos
‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py                    # Preprocesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ train_model.py                   # Entrenamiento modelo residuos
‚îÇ   ‚îú‚îÄ‚îÄ train_classifier.py              # Entrenamiento clasificadores
‚îÇ   ‚îú‚îÄ‚îÄ predict_anomalies.py             # Predicci√≥n en datos nuevos
‚îÇ   ‚îú‚îÄ‚îÄ generate_reports.py              # Generaci√≥n de reportes
‚îÇ   ‚îî‚îÄ‚îÄ __init__.py
‚îÇ
‚îú‚îÄ‚îÄ üìÇ configs/
‚îÇ   ‚îú‚îÄ‚îÄ config.py                        # Configuraci√≥n global
‚îÇ   ‚îî‚îÄ‚îÄ settings.py                      # Par√°metros ajustables
‚îÇ
‚îú‚îÄ‚îÄ üìÇ app/
‚îÇ   ‚îî‚îÄ‚îÄ main.py                          # Interfaz Streamlit
‚îÇ
‚îú‚îÄ‚îÄ üìÇ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                             # Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ imbalance/                   # Datos desbalanceo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ misalignment/                # Datos desalineaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ reports/                         # Reportes generados
‚îÇ
‚îú‚îÄ‚îÄ üìÇ models/
‚îÇ   ‚îî‚îÄ‚îÄ trained/                         # Modelos entrenados
‚îÇ       ‚îú‚îÄ‚îÄ residuals_CSP_v3.pkl         # Modelo residuos
‚îÇ       ‚îú‚îÄ‚îÄ classifier_linear.pkl
‚îÇ       ‚îú‚îÄ‚îÄ classifier_logistic.pkl
‚îÇ       ‚îú‚îÄ‚îÄ classifier_gmm.pkl
‚îÇ       ‚îú‚îÄ‚îÄ classifier_best.pkl
‚îÇ       ‚îî‚îÄ‚îÄ best_classifier_metadata.json
‚îÇ
‚îú‚îÄ‚îÄ üìÇ mlruns/                           # MLflow experiments
‚îú‚îÄ‚îÄ üìÇ mlartifacts/                      # MLflow artifacts
‚îÇ
‚îú‚îÄ‚îÄ üìÇ .github/workflows/
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_on_data_change.yml    # Trigger preprocesamiento
‚îÇ   ‚îî‚îÄ‚îÄ preprocess_on_pipeline_change.yml # Trigger por cambios
‚îÇ
‚îú‚îÄ‚îÄ Dockerfile                           # Docker image
‚îú‚îÄ‚îÄ docker-compose.yml                   # Services (MLflow + API)
‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias Python
‚îú‚îÄ‚îÄ .env                                 # Variables de entorno
‚îú‚îÄ‚îÄ .gitignore
‚îî‚îÄ‚îÄ README.md                            # Este archivo
```

---

## üì¶ Requisitos

### Sistema
- **Python**: 3.11+
- **Docker**: 24.0+ (opcional, para servicios)
- **RAM**: 4GB+ (entrenamiento)
- **CPU**: 2+ n√∫cleos

### Dependencias Python

```txt
# Core ML/Data
pandas==2.2.0
numpy==1.24.3
scikit-learn==1.3.2
scipy==1.11.4

# Modelos
scikit-learn==1.3.2

# Visualizaci√≥n
matplotlib==3.8.2
seaborn==0.13.0

# Web/API
streamlit==1.28.1
fastapi==0.104.1
uvicorn==0.24.0

# MLflow (Tracking)
mlflow==2.9.0

# Utilities
python-dotenv==1.0.0
pydantic==2.4.2
joblib==1.3.2

# Desarrollo
pytest==7.4.3
black==23.12.0
flake8==6.1.0
```

---

## ‚öôÔ∏è Instalaci√≥n

### 1. Clonar Repositorio

```bash
git clone https://github.com/tu-usuario/hydro-turb-ai-anomaly.git
cd hydro-turb-ai-anomaly
```

### 2. Crear Entorno Virtual

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# o
.venv\Scripts\activate  # Windows
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Configurar Variables de Entorno

```bash
cp .env.example .env
# Editar .env con tus valores
```

### 5. Descargar Datos (si aplica)

```bash
# Colocar archivos CSV en data/raw/
# Estructura esperada:
# data/
# ‚îú‚îÄ‚îÄ raw/
# ‚îÇ   ‚îú‚îÄ‚îÄ desbalanceo_archivo1.csv
# ‚îÇ   ‚îú‚îÄ‚îÄ desbalanceo_archivo2.csv
# ‚îÇ   ‚îú‚îÄ‚îÄ desalineacion_archivo1.csv
# ‚îÇ   ‚îî‚îÄ‚îÄ ...
```

---

## üöÄ Uso

### Ejecutar como M√≥dulo

Todos los scripts deben ejecutarse como **m√≥dulos** desde la ra√≠z del proyecto:

```bash
python -m workflows.nombre_script
```

### 1Ô∏è‚É£ An√°lisis Exploratorio (EDA)

```bash
python -m workflows.eda
```

**Salida:**
- Estad√≠sticas descriptivas
- Distribuciones por sensor
- Gr√°ficas en `data/reports/eda/`
- Perfiles de cada archivo

---

### 2Ô∏è‚É£ Preprocesamiento

```bash
python -m workflows.preprocess
```

**Salida:**
- `data/processed/imbalance/` - Datos desbalanceo
- `data/processed/misalignment/` - Datos desalineaci√≥n
- Estad√≠sticas de normalizaci√≥n
- Detecci√≥n de valores at√≠picos

---

### 3Ô∏è‚É£ Entrenar Modelo de Residuos

```bash
python -m workflows.train_model
```

**Par√°metros (en `configs/config.py`):**
```python
POLYNOMIAL_DEGREE = 3  # Grado del polinomio
TEST_SIZE = 0.2        # Proporci√≥n test
RANDOM_STATE = 42
```

**Salida:**
- `models/trained/residuals_CSP_v3.pkl` - Modelo serializado
- M√©tricas de ajuste por sensor
- Gr√°ficas de residuos en `mlartifacts/`
- Experimento registrado en MLflow

---

### 4Ô∏è‚É£ Entrenar Clasificadores

```bash
python -m workflows.train_classifier
```

**M√©todos entrenados:**
1. **Linear** - Interpolaci√≥n basada en percentiles
2. **Logistic** - Regresi√≥n log√≠stica (sklearn)
3. **GMM** - Gaussian Mixture Model

**Salida:**
- `models/trained/classifier_*.pkl` - 3 clasificadores
- `models/trained/classifier_best.pkl` - Mejor modelo (por test accuracy)
- `models/trained/best_classifier_metadata.json` - Metadata del mejor
- Comparativas en MLflow (train vs test, ROC curves, etc.)

**Selecci√≥n del mejor:**
```
Si test_accuracy igual: Logistic > GMM > Linear
Detecta overfitting autom√°ticamente (gap > 0.15)
```

---

### 5Ô∏è‚É£ Hacer Predicciones

```bash
python -m workflows.predict_anomalies
```

**Entrada:** Archivo CSV en `data/processed/imbalance/`

**Salida:**
- Clasificaci√≥n global (Desbalanceo/Desalineaci√≥n)
- Probabilidades (P(Desbal), P(Desalin))
- Severidad por sensor (Verde/Amarillo/Rojo)
- Gr√°ficas en `models/predictions/`
- Reporte JSON con resultados

**Ejemplo salida:**
```json
{
  "prediction": "DESBALANCEO",
  "confidence": 0.98,
  "probabilities": {
    "desbalanceo": 0.98,
    "desalineacion": 0.02
  },
  "severity": {
    "CSP": "VERDE",
    "CSL": "AMARILLO",
    "CTP": "VERDE",
    "CTL": "ROJO"
  }
}
```

---

### 6Ô∏è‚É£ Ejecutar Interfaz Web (Streamlit)

```bash
streamlit run app/main.py
```

**URL Local:** `http://localhost:8501`

**Tabs:**
1. **Predicci√≥n Global**
   - Clasificaci√≥n y confianza
   - Distribuci√≥n de fen√≥menos (puntos de desbalanceo vs desalineaci√≥n)
   - Informaci√≥n del an√°lisis

2. **Gr√°ficas por Sensor**
   - Datos reales vs predicci√≥n (scatter plot)
   - Ajuste polin√≥mico (l√≠nea roja)
   - Residuos (relleno gris)
   - Colorbar con magnitud de residuos

3. **Severidad Detallada**
   - Tabla por sensor con valoraci√≥n
   - Resumen de estados (Verde/Amarillo/Rojo)
   - Recomendaciones autom√°ticas

**Uso:**
1. Cargar archivo CSV desde sidebar
2. Esperar procesamiento
3. Ver an√°lisis en los tabs

---

## üê≥ Docker & MLflow

### Iniciar Servicios (Dev)

```bash
docker-compose up -d
```

**Servicios:**
- **MLflow**: `http://localhost:5000` - Tracking de experimentos
- **API**: `http://localhost:8000` - (Legado, no en uso actualmente)

**Volumes:**
```
./mlruns -> /mlflow/mlruns              (Backend store)
./mlartifacts -> /mlflow/mlartifacts    (Artifact store)
./ -> /app                               (C√≥digo)
./data -> /app/data                      (Datos)
```

### Detener Servicios

```bash
docker-compose down
```

### Ver Logs

```bash
docker-compose logs -f mlflow
docker-compose logs -f api
```

---

## ü§ñ API REST (Legado)

> **Nota:** La API FastAPI ya no est√° en uso. Toda la l√≥gica est√° en Streamlit.
> Se mantiene aqu√≠ para referencia hist√≥rica.

### Endpoint: POST `/predict`

```bash
curl -X POST "http://localhost:8000/predict" \
  -F "file=@data/processed/imbalance/archivo.csv"
```

**Response:**
```json
{
  "prediction": "DESBALANCEO",
  "confidence": 0.95,
  "probabilities": {
    "desbalanceo": 0.95,
    "desalineacion": 0.05
  },
  "metadata": {
    "samples_analyzed": 1135,
    "nominal_speed": 279.18,
    "sensors": ["CSP", "CSL", "CTP", "CTL"],
    "sensor_data": {
      "CSP": {
        "original": [...],
        "predicted": [...],
        "mean_residual": 1.3029
      }
    }
  },
  "severity": {
    "CSP": "VERDE",
    "CSL": "AMARILLO",
    "CTP": "VERDE",
    "CTL": "ROJO"
  }
}
```

---

## üìä Workflows de CI/CD

### Workflows Actuales

**`.github/workflows/`:**

- `preprocess_on_data_change.yml` - Dispara preprocesamiento al cambiar datos
- `preprocess_on_pipeline_change.yml` - Dispara al cambiar pipeline.py

### Workflows Pendientes (TODO)

Los siguientes workflows necesitan completarse:

```yaml
# 1. test_on_pr.yml
# Ejecuta pytest cuando hay PR
# - Validar sintaxis
# - Pruebas unitarias
# - Lint (flake8, black)

# 2. train_model_scheduled.yml
# Entrenamiento autom√°tico semanal
# - Trigger: cron (semanal)
# - Entrenar modelo residuos
# - Entrenar clasificadores
# - Comparar con anterior
# - Notificar resultados

# 3. deploy_streamlit.yml
# Deploy autom√°tico a Streamlit Cloud
# - Trigger: push a main
# - Verificar tests
# - Deploy a producci√≥n
# - Verificar salud

# 4. data_validation.yml
# Validaci√≥n de datos nuevos
# - Trigger: nuevos CSVs en data/raw
# - Validar formato
# - Detectar anomal√≠as
# - Alertar si hay problemas

# 5. model_registry.yml
# Registro de modelos
# - Trigger: nuevo best classifier
# - Guardar en model registry
# - Versionado (MLflow)
# - Tracking de performance
```

---

## üåê Deployment

### Streamlit Cloud (Producci√≥n)

**URL:** [Turbina Anomaly Detector](https://hydro-turb-ai-anomaly-hpzpvsmfjrv4gdlcxyxvjg.streamlit.app/)

**Pasos para Deploying:**

1. **Conectar GitHub a Streamlit Cloud**
   ```
   https://share.streamlit.io/ -> "New app" -> Seleccionar repo
   ```

2. **Configurar**
   ```
   - Repository: tu-usuario/hydro-turb-ai-anomaly
   - Branch: main
   - Main file path: app/main.py
   - Python version: 3.11
   ```

3. **Environment (Secrets)**
   ```
   # .streamlit/secrets.toml
   MLFLOW_TRACKING_URI = "http://localhost:5000"
   ```

4. **Deploy**
   - Autom√°tico con cada push a `main`
   - Logs en Streamlit dashboard

---

## üìö Documentaci√≥n T√©cnica

### Modelo de Residuos

**Clase:** `DataResidualsProcessor` (`src/models/residuals_model.py`)

```python
# Entrada: DataFrame con sensores + KPH
# Proceso:
# 1. Por cada sensor:
#    - Ajuste polinomio c√∫bico (KPH vs amplitud)
#    - Predicci√≥n = polinomio(KPH)
#    - Residuo = amplitud real - predicci√≥n
# 2. Retorna matriz de residuos (n_samples, n_sensores)

# Salida: Residuos, Columnas, KPH, Datos, Predicciones
```

**Uso:**
```python
from src.models.residuals_model import DataResidualsProcessor

model = DataResidualsProcessor.load("models/trained/residuals_CSP_v3.pkl")
residuals, cols, kph, data, pred = model.calculate_residuals_global(df)
```

---

### Clasificadores

**Clase:** `AnomalyClassifier` (`src/models/classifier.py`)

**M√©todos:**

| M√©todo | Par√°metro | Descripci√≥n |
|--------|-----------|-------------|
| Linear | N/A | Umbrales percentil (p25/p75) |
| Logistic | C=1.0 | Regresi√≥n log√≠stica sklearn |
| GMM | n_components=2 | Gaussian Mixture Model |

**Probabilidades:**
```python
# Todos retornan P(Desalineaci√≥n)
# P(Desbalanceo) = 1 - P(Desalineaci√≥n)

y_proba = classifier.predict_proba(X_test)  # shape: (n, 1)
```

---

### Severidad

**Clase:** `VibrationSeverityChecker` (`src/models/vibration_severity_checker.py`)

**Umbrales por Sensor (Francis Horizontal):**

| Sensor | Verde | Amarillo | Rojo |
|--------|-------|----------|------|
| CSP    | ‚â§60   | 60-100   | >100 |
| CSL    | ‚â§70   | 70-110   | >110 |
| CTP    | ‚â§80   | 80-120   | >120 |
| CTL    | ‚â§2.5  | 2.5-5    | >5   |

**Configurables en `configs/config.py`:**
```python
SEVERITY_THRESHOLDS = {
    "Francis horizontal": {
        "CSP": {"verde": 60, "amarillo": 100},
        "CSL": {"verde": 70, "amarillo": 110},
        # ...
    }
}
```

---

### Estructura de Datos

**Entrada CSV (raw):**
```csv
Fecha,KPH,CSP,CSL,CTP,CTL
2024-01-15 10:30:00,100.5,65.2,72.1,85.3,2.1
2024-01-15 10:31:00,100.6,65.4,72.3,85.5,2.0
...
```

**Salida Predicci√≥n:**
```python
{
    "prediction": "DESBALANCEO",               # Clasificaci√≥n global
    "confidence": 0.95,                        # Confianza del mejor model
    "probabilities": {
        "desbalanceo": 0.95,
        "desalineacion": 0.05
    },
    "metadata": {
        "samples_analyzed": 1135,
        "nominal_speed": 279.18,
        "sensors": ["CSP", "CSL", "CTP", "CTL"],
        "n_anomalies": 835,
        "sensor_data": {
            "CSP": {
                "original": [65.2, 65.4, ...],
                "predicted": [64.1, 64.3, ...],
                "residual": [1.1, 1.1, ...],
                "abs_residual": [1.1, 1.1, ...],
                "mean_residual": 1.3029
            }
        },
        "kph": [100.5, 100.6, ...]
    },
    "severity": {
        "CSP": "VERDE",
        "CSL": "AMARILLO",
        "CTP": "VERDE",
        "CTL": "ROJO"
    }
}
```

---

## üîç Comandos √ötiles

### Development

```bash
# Linting
flake8 src/ workflows/ app/

# Format
black src/ workflows/ app/

# Tests (cuando est√©n implementados)
pytest tests/ -v

# Ver estructura
tree -L 3 -I '__pycache__|*.pyc|.venv'
```

### MLflow

```bash
# Abrir dashboard
mlflow ui --backend-store-uri file:./mlruns

# Ver experimentos
mlflow experiments list

# Ver runs de un experimento
mlflow runs list --experiment-name "classifier_training"
```

### Streamlit

```bash
# Dev local
streamlit run app/main.py

# Deploy (si est√° conectado)
streamlit deploy

# Clear cache
streamlit cache clear
```

---

## üö® Troubleshooting

### Problema: "No hay datos gr√°ficos para sensor X"

**Causa:** `sensor_data` no est√° siendo poblado correctamente

**Soluci√≥n:**
```python
# Verificar que TurbinePredictor devuelve sensor_data
result = predictor.predict(temp_path)
assert "sensor_data" in result["metadata"]
```

### Problema: Severidad muestra 0.00

**Causa:** `max_values` no est√° en el nivel correcto

**Soluci√≥n:**
```python
# max_values debe estar en result, no en metadata
max_vals = result.get("max_values", {})  # Correcto
# NO
max_vals = result["metadata"].get("max_values", {})  # Incorrecto
```

### Problema: MLflow no conecta desde Docker

**Causa:** URL de MLflow incorrecta

**Soluci√≥n:**
```python
# Dentro del container, usar nombre del service
import os
mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000"))
```

### Problema: Port 8000/5000 ya en uso

**Soluci√≥n:**
```bash
# Linux/macOS
lsof -i :8000
kill -9 <PID>

# Windows
netstat -ano | findstr :8000
taskkill /PID <PID> /F
```

---

## üìù Pr√≥ximos Pasos

- [ ] Implementar workflows de CI/CD completos
- [ ] Agregar pruebas unitarias (`tests/`)
- [ ] Documentaci√≥n de API OpenAPI (si se reactiva)
- [ ] Dashboard adicional con hist√≥rico de predicciones
- [ ] Alerts autom√°ticos por correo si Rojo
- [ ] Versionado de modelos en Production
- [ ] Monitoreo de data drift

---

## üë• Contribuciones

1. Fork el proyecto
2. Crear rama feature (`git checkout -b feature/nombre`)
3. Commit cambios (`git commit -am 'Agregar feature'`)
4. Push a rama (`git push origin feature/nombre`)
5. Abrir Pull Request

---

## üìÑ Licencia

MIT License - Ver `LICENSE` para detalles

---

## üìß Contacto

Para preguntas o issues:
- Abrir GitHub Issue
- Contactar equipo de desarrollo

---

**√öltima actualizaci√≥n:** Noviembre 2025  
**Versi√≥n:** 1.0.0
